
### Hyperparameters
NEURONS: 30
INDIVIDUALS: 60
GENERATIONS: 40000
NUMBER_PROCESSES: 30
SIM_TIME: 40            # max 40 secs

# Dataset loading and saving options
ANTI_OVERFITTING:         True
DIFFERENT_DATASET_EVERY_GENERATION: 1
SAVE_TEST_SOLUTION_STEPSIZE: 100  #every .. steps the solution to the test case is calculated and saved
DATASET_DIR: "Sim_data/height_control_PID/medium_steps"
START_DATASETS_IN_MIDDLE: False


LAYER_SETTING:
  l0:
    enabled:                   True   # REQ: -                                            #NOTE: 
    neurons:                   30     # REQ: w_diagonal false, when shared N must be even #NOTE: 
    bias:                      True   # REQ: -                                            #NOTE: -
    shared_weight_and_bias:    True   # REQ: -                                            #NOTE: -
    shared_leak_i:             True   # REQ: -                                            #NOTE: -
    clamp_v:                   False  # REQ: -                                            #NOTE: -

  l1:   
     recurrent:                True   # REQ: -                                            #NOTE: -

     adaptive:                 True   # REQ: -                                            #NOTE: -
     adapt_thres_input_spikes: True   # REQ: adaptive & (diagonal or size l0 = l1)        #NOTE: t is not calc based on own spikes but incomming spikes.
     adapt_2x2_connection:     True   # REQ: adaptive & (diagonal or size l0 = l1)        #NOTE: add_t = diagonal_block_diagram(2x2)
     adapt_share_add_t:        True   # REQ: adapt_2x2_connection                         #NOTE: 2x2 blocks are linked ([[-a1,a1],[a1,-a1]])

     bias:                     False  # REQ: -                                            #NOTE: -
     w_diagonal:               True  # REQ: -                                             #NOTE: If true --> 1x1 diag, unless w_diag_2x2 is true
     w_diagonal_2x2:           True  # REQ: w_diagonal                                    #NOTE: -     
     shared_weight_and_bias:   True   # REQ: -                                            #NOTE: [[w1,w1,w2,w2,w3,w3],[w1,w1,w2,w2,w3,w3],[w4,w4,w5,w5,w6,w6], ....] shape(out,in)

     shared_leak_i:            True   # REQ: -                                            #NOTE: leak_i = [l1, l1, l2, l2, l3, l3 ...]
     clamp_v:                  False  # REQ: -                                            #NOTE: clamp the mem pot to zero  

  l2: 
     complementary_leak:       True   # REQ: -                                            #NOTE: -
     shared_weight_and_bias:   True   # REQ: -                                            #NOTE: -

FITNESS_FUNCTION: "mae"       #"mse", "mse+p", "mae" or "mae+p"
TARGET_FITNESS: 3   
#1) "pid output"        : NO dynamic system simulated     Fitness: MSE + Pearson
#2) "system reference"  : Dynamic system simulated        Fitness: MSE
#3) "pid system output" : Dynamic system simulated        Fitness: MSE + Pearson

# //TODO ONLY USE THESE WHEN DIFFERENT STRUCTURE OF DATASET IS USE
ALTERNATIVE_INPUT_COLUMN: null
ALTERNATIVE_TARGET_COLUMN: null

###################################
###################################
### Dynamics settings Blimp
DZ_INITIAL: 0
Z_INITIAL: 0
TIME_STEP: 0.01


### Less frequenty changed parameters
DATASET_NUMBER: null
# START_DATASETS_IN_MIDDLE: False

TEST_DATA_FILE: "test_dataset"
ALGORITHM: "pycma" #cmaes or pycma
WANDB_LOG:          True
SAVE_LAST_SOLUTION: True
SHOW_PLOTS:         False




#####################################################################################################################################
#########################################   Initial conditions   #####################################################################

# There are two optinons: either manually (with prev solution or hardcoded) setting the parameters or using a mean value and a gaussian 
# distribution. If it is not set manually, then it it automatically set via mean and gaussian

######## MEAN
#Options: 
# 1) "previous":  Previous solution
# 2) "same for all": All paramaters all initialized using th same method
# 3) "custom":  Every parameters can be initialized using a different method

MEAN_SETTING: "same for all" # "previous", "same for all" or "custom"  


################################################################################################
PREVIOUS_SOLUTION: 38-smart-blaze  # Null or the name of the prev saved soltion (without .pkl)
SAME_FOR_ALL: "range"      # Either Null or "manual"/"gaussian"/"range"
CUSTOM:
  l1.neuron.leak_i: "manual"
  l1.neuron.leak_v: "gaussian"
  l1.neuron.thresh: "range"
  l1.rec.weight:    "range"
  l1.ff.weight:     "range"
  l1.ff.bias:       "range"

  l2.neuron.leak:   "range"
  l2.ff.weight:     "range"


### Manual
# manual:
#   l1.ff.weight: [1.2, 1.2, 1.2, 1.2, 1,1,1,1, -1.2,-1.2,-1.2,-1.2, -1, -1, -1, -1]
#   l2.ff.weight: [0.25,0.25,0.25,0.25, -0.25,-0.25,-0.25,-0.25, 0.25,0.25,0.25,0.25, -0.25,-0.25,-0.25,-0.25]
#   l1.neuron.leak_i: [0.01,0.01,0.01,0.01, 0.2,0.1,0.2,0.1, 0.01,0.01,0.01,0.01, 0.2,0.1,0.2,0.1,]

### Gaussian and range
#The Bound Booleans are only valid when the coresponding shared layer setting is set to false
INIT_LEAKI_HALF_ZERO: False                # Set the leak_i of the first 5 neurons to close to zero
INIT_W2_Q2_Q4_NEG:    False
INIT_W1_H2_NEG:       False

gaussian:
  l1.neuron.leak_i: 0.9
  l1.neuron.leak_v: 0.9
  l1.neuron.thresh: 1
  l1.rec.weight: 0.001
  l1.ff.weight: 1
  l1.ff.bias: 0.5
  l2.neuron.leak: 0.9
  l2.ff.weight: 0.20 

range: #keep all positive (NOTE: initilaizing close to zero (in combi with the std) could lead to sign flipped initializations)
  l0.neuron.leak_i: [0.1   , 0.9]
  l0.neuron.leak_v: [0.1   , 0.9]
  l0.neuron.thresh: [0.8   , 1.2]
  l0.ff.weight:     [1     , 1.5]
  l0.ff.bias:       [0.2   , 0.5]

  l1.neuron.leak_i: [0.1   , 0.9]
  l1.neuron.leak_v: [0.1   , 0.9]
  l1.neuron.thresh: [0.8   , 1.2]
  l1.rec.weight:    [0.001 , 0.002]
  l1.ff.weight:     [1     , 1.5]
  l1.ff.bias:       [0.2   , 0.5]
  l1.neuron.leak_t: [0.1   , 0.9]
  l1.neuron.base_t: [1     , 2]
  l1.neuron.add_t:  [0.01 , 0.3]

  l2.neuron.leak:   [0.899 , 0.901]
  l2.ff.weight:     [0.1  , 0.15] 

######## STD
PERCENT_INTIIAL_STEPSIZE: 0.005



#####################################################################################################################################
#########################################   Bounds   #####################################################################

#The Bound Booleans are only valid when the coresponding shared layer setting is set to false
BOUND_LEAKI_HALF_ZERO: False  #Second half of neurons leak is zero
BOUND_W2_Q2_Q4_NEG: False    #Q1,Q3 postive and Q2,Q4 negative
BOUNDS_W1_H2_NEG: False      #Second half of neurons w1 is zero

PARAMETER_BOUNDS: #null if None in python
  l0.ff.weight:     {"low": -1.5, "high": 1.5 }  #also negative!
  l0.ff.bias:       {"low": -1,   "high": 1   }  #also negative!
  l0.neuron.leak_i: {"low": 0,    "high": 0.99}
  l0.neuron.leak_v: {"low": 0,    "high": 1   }
  l0.neuron.thresh: {"low": 0.8,  "high": 10  }

  l1.neuron.leak_i: {"low": 0,    "high": 0.99}
  l1.neuron.leak_v: {"low": 0,    "high": 1   }
  l1.neuron.thresh: {"low": 0.8,  "high": 10  }
  l1.neuron.leak_t: {"low": 0,    "high": 0.99}
  l1.neuron.base_t: {"low": 0,    "high": 2   }
  l1.neuron.add_t:  {"low": -1,   "high": 1   }
  l1.rec.weight:    {"low": -0.2, "high": 0.2 }
  l1.ff.weight:     {"low": -1.5, "high": 1.5 }  #also negative!
  l1.ff.bias:       {"low": -1,   "high": 1   }  #also negative!

  l2.neuron.leak:   {"low": 0.88, "high": 0.92}
  l2.ff.weight:     {"low": -0.30,"high": 0.30}  #also negative!


